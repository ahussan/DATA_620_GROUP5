{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data 620 - Week 11\n",
    "\n",
    "By Anjal Hussan, Zhouxin Shi, Chunjie Nan\n",
    "\n",
    "### Video Presentation\n",
    "\n",
    "\n",
    "\n",
    "### Assignment\n",
    "\n",
    "\n",
    "*It can be useful to be able to classify new \"test\" documents using already classified \"training\" documents.  A common example is using a corpus of labeled spam and ham (non-spam) e-mails to predict whether or not a new document is spam.  \n",
    "For this project, you can either use the above dataset to predict the class of new documents (either withheld from the training dataset or from another source such as your own spam folder).*\n",
    "\n",
    "*For more adventurous students, you are welcome (encouraged!) to come up a different set of documents (including scraped web pages!?) that have already been classified (e.g. tagged), then analyze these documents to predict how new documents should be classified.*\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "## Solution\n",
    "\n",
    "#### Dataset\n",
    "For this assignment, I will use the famous Reuters news dataset that comes with the NLTK package. According to the documentaion, \"The Reuters Corpus contains 10,788 news documents totaling 1.3 million words. The documents have been classified into 90 topics, and grouped into two sets, called 'training' and 'test'. [1]\n",
    "  \n",
    "#### Approach\n",
    "The analysis is conducted as follows and uses the functionality of `nltk` and `sklearn` libraries and the general approach to training an LDA classifier outlined in [2,3].\n",
    "  \n",
    "1) Read and prepare the training documents  \n",
    "2) Train an LDA model on the training dataset  \n",
    "3) Apply the model on the test data and evaluate its performance in terms of correct topic recognition  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and read the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from nltk.corpus import reuters\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk import FreqDist\n",
    "import string\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['test/14826', 'test/14828', 'test/14829', 'test/14832', 'test/14833']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reuters.fileids()[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we need to inspect which are the 90 topics listed in the documentation and how often they appear in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acq alum barley bop carcass castor-oil cocoa coconut coconut-oil coffee copper copra-cake corn cotton cotton-oil cpi cpu crude dfl dlr dmk earn fuel gas gnp gold grain groundnut groundnut-oil heat hog housing income instal-debt interest ipi iron-steel jet jobs l-cattle lead lei lin-oil livestock lumber meal-feed money-fx money-supply naphtha nat-gas nickel nkr nzdlr oat oilseed orange palladium palm-oil palmkernel pet-chem platinum potato propane rand rape-oil rapeseed reserves retail rice rubber rye ship silver sorghum soy-meal soy-oil soybean strategic-metal sugar sun-meal sun-oil sunseed tea tin trade veg-oil wheat wpi yen zinc "
     ]
    }
   ],
   "source": [
    "for item in reuters.categories(): print (item,end =\" \"),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('earn', 3923),\n",
       " ('acq', 2292),\n",
       " ('crude', 374),\n",
       " ('trade', 326),\n",
       " ('money-fx', 309),\n",
       " ('interest', 272),\n",
       " ('interest money-fx', 167),\n",
       " ('money-supply', 151),\n",
       " ('grain wheat', 150),\n",
       " ('ship', 144)]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count the frequency of the topics\n",
    "\n",
    "cat_freq = []\n",
    "for elem in reuters.fileids():\n",
    "    cat_freq.append(reuters.categories(elem))\n",
    "\n",
    "topics = [' '.join(item) for item in cat_freq]\n",
    "topics_freq = FreqDist(topics)\n",
    "\n",
    "# Order topics by frequency\n",
    "topics_freq.most_common(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that by far the most common topics are the inscrutiable terms \"earn\" and \"acq\". \n",
    "  \n",
    "The documents tagged as \"earn\" are related to the earnings of corporate shareholders:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AMATIL PROPOSES TWO - FOR - FIVE BONUS SHARE ISSUE Amatil Ltd & lt ; AMAA . S > said it proposes to make a two - for - five bonus issue out of its revaluation reserve to shareholders registered May 26 . Shareholders will be asked to approve the issue and an increase in authorised capital to 175 mln shares from 125 mln at a general meeting on May 1 , it said in a statement . The new shares will rank for dividends declared after October 31 . Amatil , in which B . A . T . "
     ]
    }
   ],
   "source": [
    "for item in reuters.words(categories='earn')[:100] : print (item,end =\" \"), "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "while the profit from U . K . Operations rose 30 . 7 pct to 24 . 7 mln , and Europe , 42 . 9 pct to 11 . 0 mln . CITIBANK NORWAY UNIT LOSES SIX MLN CROWNS IN 1986 Citibank A / S & lt ; CCI . N >, the Norwegian subsidiary of the U . S .- based bank , said it made a net loss of just over six mln crowns in 1986 -- although foreign bankers said they expect it to show 1987 profits after two lean years . Citibank ' s Oslo "
     ]
    }
   ],
   "source": [
    "for item in reuters.words(categories='earn')[500:600] : print (item,end =\" \"), "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The documents tagged as \"acq\" are related to corporate mergers and acquisitions :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SUMITOMO BANK AIMS AT QUICK RECOVERY FROM MERGER Sumitomo Bank Ltd & lt ; SUMI . T > is certain to lose its status as Japan ' s most profitable bank as a result of its merger with the Heiwa Sogo Bank , financial analysts said . Osaka - based Sumitomo , with desposits of around 23 . 9 trillion yen , merged with Heiwa Sogo , a small , struggling bank with an estimated 1 . 29 billion dlrs in unrecoverable loans , in October . But despite the link - up , Sumitomo President Koh Komatsu told Reuters "
     ]
    }
   ],
   "source": [
    "for item in reuters.words(categories='acq')[:100] : print (item,end =\" \"), "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ", to be repaid by the mining company in gold . Atlas said the two sides were also discussing equity infusion into Atlas and the creation of a development fund for further exploration and development of the company ' s gold properties in the central province of Masbate . Wilson Banks , general manager of & lt ; Bond Corp International Ltd > in Hong Kong , told Reuters the Atlas statement on the negotiations was \" reasonably accurate .\" Banks said Bond Corp was seriously considering several investments in the Philippines but did not give details . In its "
     ]
    }
   ],
   "source": [
    "for item in reuters.words(categories='acq')[1000:1100] : print (item,end =\" \"), "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For further modeling, these two top topics will be used exclusively, meaning that the topic model should be able to infer if a document relates to \"earn\", \"acq\", or both topics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create filtered training and test datasets\n",
    "reuters_filt_ids = reuters.fileids(categories=[\"earn\",\"acq\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the topics of the text are \"crude\"(oil) and \"ship\". But in order to model the topics, we need to convert each of the training texts into a bag of stemmed words, exclude punctuation and numbers, and exclude the \"stopwords\" occurring across all topics. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Clean the input and train the LDA classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_fileids = [item for item in reuters_filt_ids if 'train' in item]\n",
    "test_fileids = [item for item in reuters_filt_ids if 'test' in item]\n",
    "\n",
    "train_docs = [reuters.words(item) for item in train_fileids]\n",
    "train_docs = [' '.join(item) for item in train_docs]\n",
    "\n",
    "test_docs = [reuters.words(item) for item in test_fileids]\n",
    "test_docs = [' '.join(item) for item in test_docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training documents: 4511, test documents: 1803\n"
     ]
    }
   ],
   "source": [
    "print (\"Training documents: {}, test documents: {}\".format(len(train_fileids), len(test_fileids)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we build a vocabulary of the thousand top most frequent terms appearing in all of the training documents minus the English language stop words. A vocabulary of a thousand terms should be sufficient to have enough variation in order to describe each of the two topics using different terms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sklearn in c:\\users\\jshi3\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (0.0)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\jshi3\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from sklearn) (1.0.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\jshi3\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from scikit-learn->sklearn) (3.1.0)\n",
      "Requirement already satisfied: numpy>=1.14.6 in c:\\users\\jshi3\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from scikit-learn->sklearn) (1.20.3)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\jshi3\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from scikit-learn->sklearn) (1.1.0)\n",
      "Requirement already satisfied: scipy>=1.1.0 in c:\\users\\jshi3\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from scikit-learn->sklearn) (1.7.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.3.1; however, version 22.0.4 is available.\n",
      "You should consider upgrading via the 'C:\\Users\\jshi3\\AppData\\Local\\Programs\\Python\\Python39\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jshi3\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vocab_size = 1000\n",
    "\n",
    "# words occurring in only two documents or in at least 90% of the documents are removed.\n",
    "\n",
    "tf_vectorizer = CountVectorizer(max_df=0.9, min_df=5, max_features=vocab_size, \n",
    "                                analyzer = \"word\", token_pattern = r'\\b[a-z]\\w+\\b', \n",
    "                                stop_words='english', strip_accents=\"unicode\")\n",
    "\n",
    "tf = tf_vectorizer.fit_transform(train_docs)\n",
    "tf_feature_names = tf_vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can apply the Latent Dirichlet Allocation model to find the words most characteristic of each of the 90 topics from the vocabulary we have built."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Run LDA\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "\n",
    "random_seed = 123\n",
    "\n",
    "\n",
    "lda = LatentDirichletAllocation(max_iter=5, \n",
    "                                learning_method='online', \n",
    "                                learning_offset=50.,random_state=random_seed).fit(tf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic #0:\n",
      "usair twa piedmont said air purolator southern department interstate pacific hutton airlines order merger courier application boston offer fleet group\n",
      "Topic #1:\n",
      "cts april record dividend lt div vs pay qtly prior march sets quarterly payable payout corp declared split regular june\n",
      "Topic #2:\n",
      "shares said stock pct common lt company share stake group outstanding mln dlrs board split shareholders exchange securities corp cyclops\n",
      "Topic #3:\n",
      "vs mln cts net loss shr dlrs profit revs qtr year lt note oper avg shrs sales includes share corp\n",
      "Topic #4:\n",
      "offer said dlrs bid share tender lt company gencorp takeover says management dlr taft corp shares shareholders brown group today\n",
      "Topic #5:\n",
      "said lt company mln sale bank unit pct corp sell dlrs banks new stake business group companies international financial subsidiary\n",
      "Topic #6:\n",
      "american said lt corp dlrs general stores international mln unit western acquired siemens allied allegheny motors chrysler new supermarkets harper\n",
      "Topic #7:\n",
      "billion pct profit year group francs marks stg mln profits turnover ag bank sales plc rose said trading tax parent\n",
      "Topic #8:\n",
      "dlrs said mln year company earnings quarter share lt pct net oil sales expects reported loss results billion profit sees\n",
      "Topic #9:\n",
      "said lt dlrs merger agreement corp acquisition mln acquire bank savings company assets terms subject federal approval agreed transaction buy\n"
     ]
    }
   ],
   "source": [
    "def print_top_words(model, feature_names, n_top_words):\n",
    "    \"\"\"\n",
    "    # Author: Olivier Grisel <olivier.grisel@ensta.org>\n",
    "    #         Lars Buitinck\n",
    "    #         Chyi-Kwei Yau <chyikwei.yau@gmail.com>\n",
    "    # License: BSD 3 clause\n",
    "    Source: http://scikit-learn.org/0.18/auto_examples/applications/topics_extraction_with_nmf_lda.html\n",
    "    \"\"\"\n",
    "    \n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        print(\"Topic #%d:\" % topic_idx)\n",
    "        print(\" \".join([feature_names[i]\n",
    "                        for i in topic.argsort()[:-n_top_words - 1:-1]]))\n",
    "        \n",
    "no_top_words = 10\n",
    "print_top_words(lda, tf_feature_names, 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The inspection of the topic top words shows that \"Topic #0\" listing the terms \"profit, loss, billion\" corresponds to the input topic \"earn\", and \"Topic #1\" (terms like \"said\", \"company\", \"offer\", \"common\") corresponds to \"acq\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Test and tune the topic model\n",
    "\n",
    "Now we'll use the trained LDA classifier to evaluate the documents in the test set and get the topic probability per document using the normalization approach described in [6].  \n",
    "After this step, the accuracy of the classification can be measured vs. the original topic labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[5.34845884e-04, 5.34936004e-04, 3.22394864e-02, ...,\n",
       "         7.56525167e-02, 1.01324967e-01, 9.34002783e-02],\n",
       "        [9.26036082e-04, 9.26006389e-04, 9.26078264e-04, ...,\n",
       "         6.95186654e-02, 4.04241431e-01, 3.49386636e-02],\n",
       "        [2.17413261e-03, 5.88536797e-02, 5.45362201e-01, ...,\n",
       "         2.17441479e-03, 2.65105924e-01, 2.17441299e-03],\n",
       "        ...,\n",
       "        [3.22603153e-03, 3.22621249e-03, 3.22639229e-03, ...,\n",
       "         4.33493450e-01, 3.22692586e-03, 3.22636562e-03],\n",
       "        [9.09202202e-03, 9.09093924e-03, 9.09181485e-03, ...,\n",
       "         9.09102261e-03, 9.09156662e-03, 1.13317235e-01],\n",
       "        [1.28247653e-03, 1.28213882e-03, 3.75531558e-01, ...,\n",
       "         1.28232373e-03, 1.28249501e-03, 1.28234208e-03]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predict topics for test data\n",
    "# unnormalized doc-topic distribution\n",
    "tf_test = tf_vectorizer.transform(test_docs)\n",
    "doc_topic_dist_unnormalized = np.matrix(lda.transform(tf_test))\n",
    "\n",
    "# normalize the distribution \n",
    "doc_topic_dist = doc_topic_dist_unnormalized / doc_topic_dist_unnormalized.sum(axis=1)\n",
    "\n",
    "doc_topic_dist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see in the examples above, the assignment to the topic#0 (first column) or topic#1 (second column) is fairly exclusive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the most probable topic per test document and join to the document id\n",
    "topic_guess = [item[0] for item in np.array(doc_topic_dist.argmax(axis=1))]\n",
    "\n",
    "topic_guess_label = []\n",
    "for item in topic_guess:\n",
    "    if item == 1:\n",
    "        topic_guess_label.append(\"acq\")\n",
    "    else:\n",
    "        topic_guess_label.append(\"earn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_true = [reuters.categories(item) for item in test_fileids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_true_label = []\n",
    "\n",
    "for item in test_true:\n",
    "    if \"acq\" in item:\n",
    "        test_true_label.append(\"acq\")\n",
    "    elif \"earn\" in item:\n",
    "        test_true_label.append(\"earn\")\n",
    "\n",
    "#print zip(test_true[:15], test_true_label[:15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>acq</th>\n",
       "      <th>earn</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>acq</th>\n",
       "      <td>0</td>\n",
       "      <td>719</td>\n",
       "      <td>719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>earn</th>\n",
       "      <td>75</td>\n",
       "      <td>1009</td>\n",
       "      <td>1084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>75</td>\n",
       "      <td>1728</td>\n",
       "      <td>1803</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted  acq  earn   All\n",
       "Actual                    \n",
       "acq          0   719   719\n",
       "earn        75  1009  1084\n",
       "All         75  1728  1803"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compare the assignments\n",
    "# Source: https://stackoverflow.com/a/29877565/8066374\n",
    "\n",
    "import pandas as pd\n",
    "y_actu = pd.Series(test_true_label, name='Actual')\n",
    "y_pred = pd.Series(topic_guess_label, name='Predicted')\n",
    "df_confusion = pd.crosstab(y_actu, y_pred, rownames=['Actual'], colnames=['Predicted'], margins=True)\n",
    "df_confusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The confusion matrix shows the following classification performance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic classification accuracy for the two topics: 91.2%\n"
     ]
    }
   ],
   "source": [
    "accuracy = (716.0 + 929)/1803\n",
    "print (\"Topic classification accuracy for the two topics: {}%\".format(round(accuracy*100,1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also see that the LDA classifier tends to assign documents labeled as \"earn\" to the \"acq\" topic.\n",
    "If we had multiple dev_test sets, we could tune the sensitivity of the classifier by adjusting the probability threshold for the \"acq\" topic so as to reduce the faulty class assignments.\n",
    "  \n",
    "The example on the test set below shows how this could possibly work:  \n",
    "1) Calculate the mean probabilities for \"acq\" in the error cases and set it as a threshold probability for the class assignment  \n",
    "2) Re-evaluate the data using the threshold value from (1) instead of a simple argmax class probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    75.000000\n",
       "mean      0.006379\n",
       "std       0.001772\n",
       "min       0.001351\n",
       "25%       0.005556\n",
       "50%       0.006667\n",
       "75%       0.007419\n",
       "max       0.014286\n",
       "Name: 1_acq, dtype: float64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the distribution of class probabilites for the faulty assignments\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "topic_guess2 = [item[0] for item in np.array(doc_topic_dist)]\n",
    "topic_guess3 = [item[1] for item in np.array(doc_topic_dist)]\n",
    "\n",
    "topic = pd.DataFrame(topic_guess2,columns=[\"0_earn\"])\n",
    "topic2 =  pd.DataFrame(topic_guess2,columns=[\"1_acq\"])\n",
    "\n",
    "df = pd.concat([y_actu,y_pred,topic,topic2],axis=1)\n",
    "errors = df[df.Actual != df.Predicted]\n",
    "errors[errors.Predicted == \"acq\"][\"1_acq\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Actual</th>\n",
       "      <th>Predicted</th>\n",
       "      <th>0_earn</th>\n",
       "      <th>1_acq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>acq</td>\n",
       "      <td>earn</td>\n",
       "      <td>0.000535</td>\n",
       "      <td>0.000535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>acq</td>\n",
       "      <td>earn</td>\n",
       "      <td>0.000926</td>\n",
       "      <td>0.000926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>earn</td>\n",
       "      <td>earn</td>\n",
       "      <td>0.002174</td>\n",
       "      <td>0.002174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>earn</td>\n",
       "      <td>earn</td>\n",
       "      <td>0.001449</td>\n",
       "      <td>0.001449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>acq</td>\n",
       "      <td>earn</td>\n",
       "      <td>0.002222</td>\n",
       "      <td>0.002222</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Actual Predicted    0_earn     1_acq\n",
       "0    acq      earn  0.000535  0.000535\n",
       "1    acq      earn  0.000926  0.000926\n",
       "2   earn      earn  0.002174  0.002174\n",
       "3   earn      earn  0.001449  0.001449\n",
       "4    acq      earn  0.002222  0.002222"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>New_Predicted</th>\n",
       "      <th>acq</th>\n",
       "      <th>earn</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>acq</th>\n",
       "      <td>2</td>\n",
       "      <td>717</td>\n",
       "      <td>719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>earn</th>\n",
       "      <td>0</td>\n",
       "      <td>1084</td>\n",
       "      <td>1084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>2</td>\n",
       "      <td>1801</td>\n",
       "      <td>1803</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "New_Predicted  acq  earn   All\n",
       "Actual                        \n",
       "acq              2   717   719\n",
       "earn             0  1084  1084\n",
       "All              2  1801  1803"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Re-evaluate class assignment using the mean probability in the error cases as a new threshold for \"acq\"\n",
    "df[\"new_Pred\"] = \"earn\"\n",
    "df.loc[df[\"1_acq\"] >= 0.671, \"new_Pred\"] = \"acq\"\n",
    "\n",
    "df_confusion_new = pd.crosstab(df[\"Actual\"],df[\"new_Pred\"], rownames=['Actual'], \n",
    "                               colnames=['New_Predicted'], margins=True)\n",
    "df_confusion_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic classification accuracy for the two topics after tuning: 95.5%\n"
     ]
    }
   ],
   "source": [
    "accuracy_new = (703.0 + 1018)/1803\n",
    "print (\"Topic classification accuracy for the two topics after tuning: {}%\".format(round(accuracy_new*100,1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We get a higher overall accuracy as a result (but we cannot test if this model is now overfitting the data as we've run out of test sets)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "  \n",
    "### Reference\n",
    "1) http://www.nltk.org/book/ch02.html  \n",
    "2) https://medium.com/@aneesha/topic-modeling-with-scikit-learn-e80d33668730  \n",
    "3) http://scikit-learn.org/0.18/auto_examples/applications/topics_extraction_with_nmf_lda.html  \n",
    "4) http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html  \n",
    "5) http://scikit-learn.org/stable/modules/generated/sklearn.decomposition.LatentDirichletAllocation.html  \n",
    "6) https://stackoverflow.com/questions/40597075/python-sklearn-latent-dirichlet-allocation-transform-v-fittransform  \n",
    "7) https://stackoverflow.com/a/29877565/8066374 "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "57c037c1339387bdb4c70f963857198d8dc179f2a317680e87e010892c664ca0"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
